{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "from sklearn import naive_bayes, neighbors\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = 'Android_Malware_Benign.csv'\n",
    "dataset = pd.read_csv(path_file)\n",
    "dataset = dataset.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset.head(5))\n",
    "# print(dataset.info())\n",
    "# print(test)\n",
    "\n",
    "\n",
    "def preprocess(dataset):\n",
    "    dataset_prepprocess = dataset.copy()\n",
    "\n",
    "    for column in dataset.columns:\n",
    "        if dataset[column].nunique()== 1:\n",
    "            # print(column)\n",
    "            dataset_prepprocess.drop(column, axis=1, inplace=True)\n",
    "\n",
    "    X = dataset_prepprocess.drop('Label', axis=1)\n",
    "\n",
    "    y = dataset_prepprocess['Label']\n",
    "\n",
    "    print(y.value_counts())\n",
    "    y = y.replace('Malware', 1)\n",
    "    y = y.replace('Benign', 0)\n",
    "\n",
    "    # split in train, test and validation in 60 20 20\n",
    "\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, X_train_val, y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "Malware    2533\n",
      "Benign     1931\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, X_train_val, y_train_val = preprocess(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB()\n",
      "Cross-Validation f1_score: 0.9176573040503962\n",
      "Cross-Validation Scores f1: [0.90264581 0.89632808 0.90571353 0.94018335 0.91009237 0.94240449\n",
      " 0.92246185 0.90571353 0.90523115 0.94579887]\n",
      "\n",
      "\n",
      "Cross-Validation accuracy: 0.9196344459571538\n",
      "Cross-Validation Scores acc: [0.90502793 0.89915966 0.90756303 0.94117647 0.91316527 0.94397759\n",
      " 0.92436975 0.90756303 0.90756303 0.94677871]\n",
      "MultinomialNB()\n",
      "Cross-Validation f1_score: 0.8691803381247499\n",
      "Cross-Validation Scores f1: [0.88911711 0.83223684 0.85757785 0.89423963 0.85386575 0.88218599\n",
      " 0.88864263 0.85658301 0.86138671 0.87596784]\n",
      "\n",
      "\n",
      "Cross-Validation accuracy: 0.8756599846642569\n",
      "Cross-Validation Scores acc: [0.89385475 0.84313725 0.8627451  0.89915966 0.8627451  0.88795518\n",
      " 0.89355742 0.8627451  0.86834734 0.88235294]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes classifier\n",
    "\n",
    "for model in [naive_bayes.BernoulliNB(), naive_bayes.MultinomialNB()]:\n",
    "    print(model)\n",
    "\n",
    "    cv_scores_f1 = cross_val_score(model, X_train_val, y_train_val, cv=10, scoring='f1_macro')\n",
    "    cv_scores_accuracy = cross_val_score(model, X_train_val, y_train_val, cv=10, scoring='accuracy')\n",
    "    print('Cross-Validation f1_score:', np.mean(cv_scores_f1))\n",
    "    print('Cross-Validation Scores f1:', cv_scores_f1)\n",
    "    print('\\n')\n",
    "    print('Cross-Validation accuracy:', np.mean(cv_scores_accuracy))\n",
    "    print('Cross-Validation Scores acc:', cv_scores_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9171332586786114\n",
      "Confusion Matrix:\n",
      "[[358  44]\n",
      " [ 30 461]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91       402\n",
      "           1       0.91      0.94      0.93       491\n",
      "\n",
      "    accuracy                           0.92       893\n",
      "   macro avg       0.92      0.91      0.92       893\n",
      "weighted avg       0.92      0.92      0.92       893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "model = naive_bayes.BernoulliNB() # best one in validation\n",
    "\n",
    "model.fit(X_train_val, y_train_val)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   criterion  max_depth  n_estimators  mean_f1_score  \\\n",
      "0       gini        NaN            10       0.951492   \n",
      "1       gini        NaN            50       0.953152   \n",
      "2       gini        NaN           100       0.953420   \n",
      "3       gini        NaN           200       0.954293   \n",
      "4       gini       10.0            10       0.945541   \n",
      "5       gini       10.0            50       0.954666   \n",
      "6       gini       10.0           100       0.956905   \n",
      "7       gini       10.0           200       0.956351   \n",
      "8       gini       20.0            10       0.952354   \n",
      "9       gini       20.0            50       0.954882   \n",
      "10      gini       20.0           100       0.955453   \n",
      "11      gini       20.0           200       0.956600   \n",
      "12      gini       30.0            10       0.947006   \n",
      "13      gini       30.0            50       0.950353   \n",
      "14      gini       30.0           100       0.954003   \n",
      "15      gini       30.0           200       0.954565   \n",
      "16   entropy        NaN            10       0.949508   \n",
      "17   entropy        NaN            50       0.954302   \n",
      "18   entropy        NaN           100       0.953428   \n",
      "19   entropy        NaN           200       0.953732   \n",
      "20   entropy       10.0            10       0.945285   \n",
      "21   entropy       10.0            50       0.954064   \n",
      "22   entropy       10.0           100       0.956347   \n",
      "23   entropy       10.0           200       0.954912   \n",
      "24   entropy       20.0            10       0.953473   \n",
      "25   entropy       20.0            50       0.956026   \n",
      "26   entropy       20.0           100       0.956594   \n",
      "27   entropy       20.0           200       0.956026   \n",
      "28   entropy       30.0            10       0.946088   \n",
      "29   entropy       30.0            50       0.955175   \n",
      "30   entropy       30.0           100       0.954311   \n",
      "31   entropy       30.0           200       0.954871   \n",
      "32  log_loss        NaN            10       0.944691   \n",
      "33  log_loss        NaN            50       0.953140   \n",
      "34  log_loss        NaN           100       0.954002   \n",
      "35  log_loss        NaN           200       0.954842   \n",
      "36  log_loss       10.0            10       0.946133   \n",
      "37  log_loss       10.0            50       0.953767   \n",
      "38  log_loss       10.0           100       0.956355   \n",
      "39  log_loss       10.0           200       0.957785   \n",
      "40  log_loss       20.0            10       0.953794   \n",
      "41  log_loss       20.0            50       0.955733   \n",
      "42  log_loss       20.0           100       0.954893   \n",
      "43  log_loss       20.0           200       0.956014   \n",
      "44  log_loss       30.0            10       0.949248   \n",
      "45  log_loss       30.0            50       0.951438   \n",
      "46  log_loss       30.0           100       0.954593   \n",
      "47  log_loss       30.0           200       0.955137   \n",
      "\n",
      "                                            f1_scores  mean_accuracy  \\\n",
      "0   [0.9545569941609545, 0.9225988292259883, 0.943...       0.954076   \n",
      "1   [0.9488766184310738, 0.9311386870700187, 0.951...       0.956033   \n",
      "2   [0.9516073885005925, 0.9225988292259883, 0.957...       0.954634   \n",
      "3   [0.9516073885005925, 0.9284540462543589, 0.957...       0.954915   \n",
      "4   [0.9403120161962606, 0.9227303699547076, 0.942...       0.948475   \n",
      "5   [0.9517516390648412, 0.93999951980408, 0.94876...       0.956595   \n",
      "6   [0.9516073885005925, 0.9369865211810013, 0.957...       0.957996   \n",
      "7   [0.9517516390648412, 0.9313725490196079, 0.951...       0.957436   \n",
      "8   [0.9489495199163418, 0.9227303699547076, 0.960...       0.948473   \n",
      "9   [0.9545569941609545, 0.9341777225540102, 0.951...       0.957155   \n",
      "10  [0.9516073885005925, 0.9255295250320925, 0.951...       0.956877   \n",
      "11  [0.9516811559684014, 0.9313725490196079, 0.957...       0.957996   \n",
      "12  [0.9405611821351485, 0.9173960569044066, 0.948...       0.949034   \n",
      "13  [0.9460753613077637, 0.9255295250320925, 0.951...       0.952675   \n",
      "14  [0.9516073885005925, 0.919801026957638, 0.9543...       0.954075   \n",
      "15  [0.9573657258544719, 0.9283322492833225, 0.960...       0.956596   \n",
      "16  [0.9376049687866401, 0.9285708569096192, 0.945...       0.947355   \n",
      "17  [0.9458279907297531, 0.9313725490196079, 0.960...       0.955756   \n",
      "18  [0.9544891148895598, 0.9168654091686541, 0.957...       0.956033   \n",
      "19  [0.9602373698908353, 0.9255295250320925, 0.954...       0.955195   \n",
      "20  [0.9343145466874078, 0.9315873522836154, 0.932...       0.949879   \n",
      "21  [0.9404821280133001, 0.9397990893979908, 0.960...       0.955475   \n",
      "22  [0.9516811559684014, 0.9368771298141838, 0.960...       0.957156   \n",
      "23  [0.9516811559684014, 0.9255295250320925, 0.954...       0.958557   \n",
      "24  [0.9544891148895598, 0.9224618503294104, 0.960...       0.954355   \n",
      "25  [0.9431113936119497, 0.9284540462543589, 0.960...       0.957158   \n",
      "26  [0.9573657258544719, 0.9369865211810013, 0.954...       0.956874   \n",
      "27  [0.9573657258544719, 0.9370915032679739, 0.954...       0.959115   \n",
      "28  [0.9374225329731447, 0.9115665827639938, 0.957...       0.942310   \n",
      "29  [0.9573657258544719, 0.9312580231065468, 0.954...       0.955756   \n",
      "30  [0.9545569941609545, 0.9196618015816884, 0.954...       0.956594   \n",
      "31  [0.9516811559684014, 0.9255295250320925, 0.957...       0.956315   \n",
      "32  [0.9402208916772024, 0.9173960569044066, 0.945...       0.949034   \n",
      "33  [0.9573657258544719, 0.9225988292259883, 0.951...       0.955197   \n",
      "34  [0.9601779755283648, 0.9168654091686541, 0.957...       0.956594   \n",
      "35  [0.9573657258544719, 0.9282054169716764, 0.957...       0.955195   \n",
      "36  [0.9488766184310738, 0.9313725490196079, 0.946...       0.943156   \n",
      "37  [0.9546217954811927, 0.9341777225540102, 0.948...       0.955757   \n",
      "38  [0.9517516390648412, 0.9370915032679739, 0.954...       0.957436   \n",
      "39  [0.9545569941609545, 0.9400934915498023, 0.954...       0.956595   \n",
      "40  [0.9546217954811927, 0.9370915032679739, 0.946...       0.949034   \n",
      "41  [0.945996586082331, 0.9368771298141838, 0.9601...       0.957718   \n",
      "42  [0.9459141400888973, 0.9340656693406566, 0.948...       0.958555   \n",
      "43  [0.9544891148895598, 0.9399013988536615, 0.954...       0.956875   \n",
      "44  [0.9460753613077637, 0.9115665827639938, 0.948...       0.949876   \n",
      "45  [0.9516073885005925, 0.9168654091686541, 0.954...       0.954075   \n",
      "46  [0.9573657258544719, 0.9312580231065468, 0.957...       0.955756   \n",
      "47  [0.9544891148895598, 0.9224618503294104, 0.954...       0.956876   \n",
      "\n",
      "                                      accuracy_scores  \n",
      "0   [0.946927374301676, 0.9411764705882353, 0.9495...  \n",
      "1   [0.9608938547486033, 0.9187675070028011, 0.960...  \n",
      "2   [0.9553072625698324, 0.927170868347339, 0.9579...  \n",
      "3   [0.952513966480447, 0.9243697478991597, 0.9607...  \n",
      "4   [0.9441340782122905, 0.9243697478991597, 0.952...  \n",
      "5   [0.9553072625698324, 0.9327731092436975, 0.960...  \n",
      "6   [0.9553072625698324, 0.9355742296918768, 0.955...  \n",
      "7   [0.952513966480447, 0.938375350140056, 0.95518...  \n",
      "8   [0.952513966480447, 0.9159663865546218, 0.9383...  \n",
      "9   [0.9553072625698324, 0.9355742296918768, 0.960...  \n",
      "10  [0.9497206703910615, 0.9355742296918768, 0.960...  \n",
      "11  [0.9553072625698324, 0.927170868347339, 0.9635...  \n",
      "12  [0.946927374301676, 0.9159663865546218, 0.9635...  \n",
      "13  [0.9497206703910615, 0.9243697478991597, 0.955...  \n",
      "14  [0.952513966480447, 0.9243697478991597, 0.9551...  \n",
      "15  [0.952513966480447, 0.9299719887955182, 0.9607...  \n",
      "16  [0.9441340782122905, 0.927170868347339, 0.9551...  \n",
      "17  [0.9497206703910615, 0.9299719887955182, 0.960...  \n",
      "18  [0.9608938547486033, 0.9215686274509803, 0.957...  \n",
      "19  [0.9553072625698324, 0.9243697478991597, 0.955...  \n",
      "20  [0.9329608938547486, 0.9299719887955182, 0.957...  \n",
      "21  [0.952513966480447, 0.9355742296918768, 0.9579...  \n",
      "22  [0.952513966480447, 0.9327731092436975, 0.9523...  \n",
      "23  [0.952513966480447, 0.9355742296918768, 0.9607...  \n",
      "24  [0.952513966480447, 0.9187675070028011, 0.9691...  \n",
      "25  [0.946927374301676, 0.9355742296918768, 0.9579...  \n",
      "26  [0.9581005586592178, 0.9327731092436975, 0.955...  \n",
      "27  [0.9581005586592178, 0.9299719887955182, 0.960...  \n",
      "28  [0.952513966480447, 0.9103641456582633, 0.9383...  \n",
      "29  [0.9497206703910615, 0.9187675070028011, 0.963...  \n",
      "30  [0.9581005586592178, 0.9243697478991597, 0.957...  \n",
      "31  [0.9553072625698324, 0.9243697478991597, 0.957...  \n",
      "32  [0.9497206703910615, 0.907563025210084, 0.9551...  \n",
      "33  [0.946927374301676, 0.927170868347339, 0.94957...  \n",
      "34  [0.9581005586592178, 0.9299719887955182, 0.960...  \n",
      "35  [0.9553072625698324, 0.9215686274509803, 0.955...  \n",
      "36  [0.9329608938547486, 0.927170868347339, 0.9439...  \n",
      "37  [0.946927374301676, 0.9327731092436975, 0.9607...  \n",
      "38  [0.952513966480447, 0.9439775910364145, 0.9495...  \n",
      "39  [0.9553072625698324, 0.9355742296918768, 0.952...  \n",
      "40  [0.9497206703910615, 0.9103641456582633, 0.957...  \n",
      "41  [0.946927374301676, 0.9299719887955182, 0.9607...  \n",
      "42  [0.9581005586592178, 0.938375350140056, 0.9551...  \n",
      "43  [0.9553072625698324, 0.9299719887955182, 0.955...  \n",
      "44  [0.9441340782122905, 0.9243697478991597, 0.957...  \n",
      "45  [0.952513966480447, 0.9215686274509803, 0.9579...  \n",
      "46  [0.952513966480447, 0.927170868347339, 0.96078...  \n",
      "47  [0.952513966480447, 0.9299719887955182, 0.9551...  \n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "results = []\n",
    "\n",
    "for criterion in ['gini', 'entropy', 'log_loss']:\n",
    "    for max_depth in [None, 10, 20, 30]:\n",
    "        for n_estimators in [10, 50, 100, 200]:\n",
    "            \n",
    "            model = RandomForestClassifier(criterion=criterion, max_depth=max_depth, n_estimators=n_estimators)\n",
    "            \n",
    "            cv_scores_f1 = cross_val_score(model, X_train_val, y_train_val, cv=10, scoring='f1_macro')\n",
    "            cv_scores_accuracy = cross_val_score(model, X_train_val, y_train_val, cv=10, scoring='accuracy')\n",
    "            \n",
    "            mean_f1 = np.mean(cv_scores_f1)\n",
    "            mean_accuracy = np.mean(cv_scores_accuracy)\n",
    "            \n",
    "            results.append({\n",
    "                'criterion': criterion,\n",
    "                'max_depth': max_depth,\n",
    "                'n_estimators': n_estimators,\n",
    "                'mean_f1_score': mean_f1,\n",
    "                'f1_scores': cv_scores_f1,\n",
    "                'mean_accuracy': mean_accuracy,\n",
    "                'accuracy_scores': cv_scores_accuracy\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 results based on F1 score:\n",
      "   criterion  max_depth  n_estimators  mean_f1_score\n",
      "39  log_loss       10.0           200       0.957785\n",
      "6       gini       10.0           100       0.956905\n",
      "11      gini       20.0           200       0.956600\n",
      "26   entropy       20.0           100       0.956594\n",
      "38  log_loss       10.0           100       0.956355\n",
      "7       gini       10.0           200       0.956351\n",
      "22   entropy       10.0           100       0.956347\n",
      "27   entropy       20.0           200       0.956026\n",
      "25   entropy       20.0            50       0.956026\n",
      "43  log_loss       20.0           200       0.956014\n",
      "\n",
      "Top 10 results based on Accuracy:\n",
      "   criterion  max_depth  n_estimators  mean_accuracy\n",
      "27   entropy       20.0           200       0.959115\n",
      "23   entropy       10.0           200       0.958557\n",
      "42  log_loss       20.0           100       0.958555\n",
      "6       gini       10.0           100       0.957996\n",
      "11      gini       20.0           200       0.957996\n",
      "41  log_loss       20.0            50       0.957718\n",
      "38  log_loss       10.0           100       0.957436\n",
      "7       gini       10.0           200       0.957436\n",
      "25   entropy       20.0            50       0.957158\n",
      "22   entropy       10.0           100       0.957156\n"
     ]
    }
   ],
   "source": [
    "# Top 10 results based on mean F1 score\n",
    "top_f1 = results_df.sort_values(by='mean_f1_score', ascending=False).head(10)\n",
    "print(\"Top 10 results based on F1 score:\")\n",
    "print(top_f1[['criterion', 'max_depth', 'n_estimators', 'mean_f1_score']])\n",
    "\n",
    "# Top 10 results based on mean accuracy\n",
    "top_accuracy = results_df.sort_values(by='mean_accuracy', ascending=False).head(10)\n",
    "print(\"\\nTop 10 results based on Accuracy:\")\n",
    "print(top_accuracy[['criterion', 'max_depth', 'n_estimators', 'mean_accuracy']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 200}\n",
      "Accuracy: 0.9552\n",
      "F1 Score: 0.9546\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       402\n",
      "           1       0.95      0.97      0.96       491\n",
      "\n",
      "    accuracy                           0.96       893\n",
      "   macro avg       0.96      0.95      0.95       893\n",
      "weighted avg       0.96      0.96      0.96       893\n",
      "\n",
      "Confusion Matrix:\n",
      " [[376  26]\n",
      " [ 14 477]]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Configuration: {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 100}\n",
      "Accuracy: 0.9574\n",
      "F1 Score: 0.9570\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       402\n",
      "           1       0.96      0.96      0.96       491\n",
      "\n",
      "    accuracy                           0.96       893\n",
      "   macro avg       0.96      0.96      0.96       893\n",
      "weighted avg       0.96      0.96      0.96       893\n",
      "\n",
      "Confusion Matrix:\n",
      " [[382  20]\n",
      " [ 18 473]]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Configuration: {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 200}\n",
      "Accuracy: 0.9563\n",
      "F1 Score: 0.9558\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       402\n",
      "           1       0.95      0.97      0.96       491\n",
      "\n",
      "    accuracy                           0.96       893\n",
      "   macro avg       0.96      0.95      0.96       893\n",
      "weighted avg       0.96      0.96      0.96       893\n",
      "\n",
      "Confusion Matrix:\n",
      " [[377  25]\n",
      " [ 14 477]]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_configs = [\n",
    "    {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 200},\n",
    "    {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 100},\n",
    "    {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 200}\n",
    "]\n",
    "\n",
    "# Test results\n",
    "test_results = []\n",
    "\n",
    "for config in best_configs:\n",
    "    model = RandomForestClassifier(\n",
    "        criterion=config['criterion'],\n",
    "        max_depth=config['max_depth'],\n",
    "        n_estimators=config['n_estimators']\n",
    "    )\n",
    "    model.fit(X_train_val, y_train_val) \n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "    class_report = classification_report(y_test, y_test_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    test_results.append({\n",
    "        'config': config,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'classification_report': class_report,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    })\n",
    "\n",
    "for result in test_results:\n",
    "    print(f\"Configuration: {result['config']}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"F1 Score: {result['f1_score']:.4f}\")\n",
    "    print(\"Classification Report:\\n\", result['classification_report'])\n",
    "    print(\"Confusion Matrix:\\n\", result['confusion_matrix'])\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features:\n",
      "1. android.permission.READ_PHONE_STATE (0.23729097987323172)\n",
      "2. com.google.android.c2dm.permission.RECEIVE (0.08394321672690427)\n",
      "3. android.permission.RECEIVE_BOOT_COMPLETED (0.08260028636978257)\n",
      "4. com.android.launcher.permission.INSTALL_SHORTCUT (0.058281860769018916)\n",
      "5. android.permission.ACCESS_FINE_LOCATION (0.04676318566613568)\n",
      "6. android.permission.ACCESS_COARSE_LOCATION (0.034635535410131195)\n",
      "7. Ljava/net/URL;->openConnection (0.026789246906548925)\n",
      "8. android.permission.WAKE_LOCK (0.02675007125228695)\n",
      "9. RECEIVE_BOOT_COMPLETED (0.026501829666032872)\n",
      "10. Landroid/location/LocationManager;->getLastKgoodwarewnLocation (0.024950426576223716)\n",
      "11. android.permission.SEND_SMS (0.01857871894096701)\n",
      "12. android.permission.READ_SMS (0.017296099112805427)\n",
      "13. GET_TASKS (0.01679634326463875)\n",
      "14. android.permission.READ_EXTERNAL_STORAGE (0.013566741130133113)\n",
      "15. android.permission.CAMERA (0.012978117642152745)\n",
      "16. android.permission.RECEIVE_SMS (0.012969360214460473)\n",
      "17. android.permission.READ_LOGS (0.012907171334778634)\n",
      "18. com.android.vending.BILLING (0.01255664723425425)\n",
      "19. WAKE_LOCK (0.011991138057974948)\n",
      "20. android.permission.GET_ACCOUNTS (0.010517037356735037)\n",
      "21. android.permission.GET_TASKS (0.010497882182853184)\n",
      "22. KILL_BACKGROUND_PROCESSES (0.00890590589475722)\n",
      "23. android.permission.READ_CONTACTS (0.00829158746095465)\n",
      "24. Ldalvik/system/DexClassLoader;->loadClass (0.00771873205231641)\n",
      "25. android.permission.ACCESS_WIFI_STATE (0.007642789146999262)\n",
      "26. com.google.android.providers.gsf.permission.READ_GSERVICES (0.0072812832307902)\n",
      "27. android.permission.CALL_PHONE (0.005738007082386845)\n",
      "28. android.permission.CHANGE_CONFIGURATION (0.005320797663449546)\n",
      "29. Landroid/telephony/TelephonyManager;->getSimOperatorName (0.004851318992386834)\n",
      "30. READ_PHONE_STATE (0.00439546844266411)\n"
     ]
    }
   ],
   "source": [
    "# print 10 best features names for the best model config\n",
    "\n",
    "model = RandomForestClassifier(criterion='gini', max_depth=10, n_estimators=100)\n",
    "model.fit(X_train_val, y_train_val)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Top 10 features:\")\n",
    "for i in range(30):\n",
    "    print(f\"{i+1}. {X_train_val.columns[indices[i]]} ({importances[indices[i]]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 results by F1 score:\n",
      "   criterion  max_depth  mean_f1_score  mean_accuracy\n",
      "7    entropy       10.0       0.942543       0.943715\n",
      "1       gini       10.0       0.938012       0.940633\n",
      "6    entropy        NaN       0.936443       0.935871\n",
      "10   entropy      100.0       0.936157       0.935311\n",
      "8    entropy       20.0       0.934177       0.940072\n",
      "11   entropy      200.0       0.933856       0.935032\n",
      "9    entropy       30.0       0.933315       0.936152\n",
      "4       gini      100.0       0.931727       0.932236\n",
      "2       gini       20.0       0.930845       0.934753\n",
      "0       gini        NaN       0.930583       0.933914\n",
      "\n",
      "Top 10 results by Accuracy:\n",
      "   criterion  max_depth  mean_f1_score  mean_accuracy\n",
      "7    entropy       10.0       0.942543       0.943715\n",
      "1       gini       10.0       0.938012       0.940633\n",
      "8    entropy       20.0       0.934177       0.940072\n",
      "9    entropy       30.0       0.933315       0.936152\n",
      "6    entropy        NaN       0.936443       0.935871\n",
      "10   entropy      100.0       0.936157       0.935311\n",
      "11   entropy      200.0       0.933856       0.935032\n",
      "2       gini       20.0       0.930845       0.934753\n",
      "3       gini       30.0       0.930558       0.934473\n",
      "0       gini        NaN       0.930583       0.933914\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "\n",
    "dt_results_list = []\n",
    "\n",
    "for criterion in ['gini', 'entropy']:\n",
    "    for max_depth in [None, 10, 20, 30, 100, 200]:  \n",
    "        model = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth)\n",
    "        \n",
    "        cv_scores_f1 = cross_val_score(model, X_train_val, y_train_val, cv=10, scoring='f1_macro')\n",
    "        cv_scores_accuracy = cross_val_score(model, X_train_val, y_train_val, cv=10, scoring='accuracy')\n",
    "        \n",
    "        mean_f1 = np.mean(cv_scores_f1)\n",
    "        mean_accuracy = np.mean(cv_scores_accuracy)\n",
    "        \n",
    "        dt_results_list.append({\n",
    "            'criterion': criterion,\n",
    "            'max_depth': max_depth,\n",
    "            'mean_f1_score': mean_f1,\n",
    "            'mean_accuracy': mean_accuracy\n",
    "        })\n",
    "\n",
    "dt_results_df = pd.DataFrame(dt_results_list)\n",
    "\n",
    "# print(dt_results_df)\n",
    "\n",
    "print(\"\\nTop 10 results by F1 score:\")\n",
    "print(dt_results_df.sort_values(by='mean_f1_score', ascending=False).head(10))\n",
    "\n",
    "print(\"\\nTop 10 results by Accuracy:\")\n",
    "print(dt_results_df.sort_values(by='mean_accuracy', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 results by F1 score:\n",
      "    kernel      C  gamma  mean_f1_score  mean_accuracy\n",
      "16     rbf   10.0   0.01       0.959199       0.959955\n",
      "14     rbf   10.0  scale       0.959131       0.959956\n",
      "20     rbf  100.0   auto       0.958577       0.959395\n",
      "0   linear    0.1  scale       0.956929       0.957713\n",
      "21     rbf  100.0   0.01       0.956573       0.957435\n",
      "15     rbf   10.0   auto       0.955738       0.956593\n",
      "1   linear    1.0  scale       0.955431       0.956317\n",
      "2   linear   10.0  scale       0.955026       0.956038\n",
      "11     rbf    1.0   0.01       0.954564       0.955474\n",
      "9      rbf    1.0  scale       0.954331       0.955193\n",
      "\n",
      "Top 5 results by Accuracy:\n",
      "    kernel      C  gamma  mean_f1_score  mean_accuracy\n",
      "14     rbf   10.0  scale       0.959131       0.959956\n",
      "16     rbf   10.0   0.01       0.959199       0.959955\n",
      "20     rbf  100.0   auto       0.958577       0.959395\n",
      "0   linear    0.1  scale       0.956929       0.957713\n",
      "21     rbf  100.0   0.01       0.956573       0.957435\n",
      "15     rbf   10.0   auto       0.955738       0.956593\n",
      "1   linear    1.0  scale       0.955431       0.956317\n",
      "2   linear   10.0  scale       0.955026       0.956038\n",
      "11     rbf    1.0   0.01       0.954564       0.955474\n",
      "9      rbf    1.0  scale       0.954331       0.955193\n"
     ]
    }
   ],
   "source": [
    "# svm \n",
    "\n",
    "svm_results_list = []\n",
    "\n",
    "for kernel in ['linear', 'rbf', 'poly']:\n",
    "    for C in [0.1, 1, 10, 100]:  \n",
    "        for gamma in ['scale', 'auto', 0.01, 0.1, 1]:\n",
    "            if kernel == 'linear' and gamma != 'scale':\n",
    "                continue  # Gamma not used in linear kernel\n",
    "\n",
    "            model = SVC(kernel=kernel, C=C, gamma=gamma)\n",
    "            \n",
    "            cv_scores_f1 = cross_val_score(model, X_train_val, y_train_val, cv=10, scoring='f1_macro')\n",
    "            cv_scores_accuracy = cross_val_score(model, X_train_val, y_train_val, cv=10, scoring='accuracy')\n",
    "            \n",
    "            mean_f1 = np.mean(cv_scores_f1)\n",
    "            mean_accuracy = np.mean(cv_scores_accuracy)\n",
    "            \n",
    "            svm_results_list.append({\n",
    "                'kernel': kernel,\n",
    "                'C': C,\n",
    "                'gamma': gamma,\n",
    "                'mean_f1_score': mean_f1,\n",
    "                'mean_accuracy': mean_accuracy,\n",
    "            })\n",
    "\n",
    "svm_results_df = pd.DataFrame(svm_results_list)\n",
    "\n",
    "# Display the top 10 configurations by F1 score and accuracy\n",
    "print(\"\\nTop 5 results by F1 score:\")\n",
    "print(svm_results_df.sort_values(by='mean_f1_score', ascending=False).head(10))\n",
    "\n",
    "print(\"\\nTop 5 results by Accuracy:\")\n",
    "print(svm_results_df.sort_values(by='mean_accuracy', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.01}\n",
      "Test F1 Score: 0.9638\n",
      "Test Accuracy: 0.9642\n",
      "\n",
      "Parameters: {'kernel': 'rbf', 'C': 10.0, 'gamma': 'scale'}\n",
      "Test F1 Score: 0.9649\n",
      "Test Accuracy: 0.9653\n",
      "\n",
      "Parameters: {'kernel': 'rbf', 'C': 100.0, 'gamma': 'auto'}\n",
      "Test F1 Score: 0.9615\n",
      "Test Accuracy: 0.9619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Top three configs \n",
    "top_parameters = [\n",
    "    {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.01},\n",
    "    {'kernel': 'rbf', 'C': 10.0, 'gamma': 'scale'},\n",
    "    {'kernel': 'rbf', 'C': 100.0, 'gamma': 'auto'}\n",
    "]\n",
    "\n",
    "for params in top_parameters:\n",
    "    model = SVC(kernel=params['kernel'], C=params['C'], gamma=params['gamma'], class_weight='balanced')\n",
    "    \n",
    "    model.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    test_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Parameters: {params}\")\n",
    "    print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
